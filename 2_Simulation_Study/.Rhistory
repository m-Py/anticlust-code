## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
15 * 10
# Repeat the simulation for K = 2 and K = 3
for (i in 1:3) {
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 150)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
}
# Load required packages
library(anticlust)
source("0-functions-matching.R")
source("0-functions-anticlustering-methods.R")
source("0-functions-generate-data.R")
# Repeat the simulation for K = 2 and K = 3
for (i in 1:3) {
for (K in 2:3) {
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated!
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 150)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
}
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
300 * 150
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
source('~/Seafile/MyStuff/anticlust-applications/OSF/2_Simulation_Study/2-Call-Methods.R', echo=TRUE)
# Author: Martin Papenberg
# Year: 2019
# Load required packages
library(anticlust)
source("0-functions-analyze-data.R")
for (K in 2) {
# Read the file that contains the solutions and compute the objectives
# for each solution.
data <- read.csv2(paste0("results-K", K, "-solutions.csv"), stringsAsFactors = FALSE)
## only compute objectives when the method was applied, i.e., remove NA rows
data <- na.omit(data)
# Compute all objectives and structure data in long format
all_objectives <- t(apply(data, 1, compute_objectives, K = K))
# make objectives numeric
all_objectives <- data.frame(all_objectives[, 1:2], apply(all_objectives[, 3:5], 2, as.numeric))
# Merge with initial data frame to have all info available
results <- merge(data, all_objectives, by = c("ID", "method"))
results$result <- NULL # remove the solution from this data frame
## Write the results to file
results_file <- paste0("results-K", K, "-objectives-raw.csv")
write.table(results, results_file, row.names = FALSE, sep = ";",
append = FALSE, col.names = TRUE)
}
# Load required packages
library(anticlust)
library(dplyr)
## Analyze data for K = 2 and K = 3 and write results to file
for (K in 2:3) {
results_file <- paste0("results-K", K, "-objectives-raw.csv")
## Read test results
ldf <- read.csv(results_file, sep = ";", stringsAsFactors = FALSE)
message("Number of simulation runs for K = ", K , ": ", length(unique(ldf$ID)), "\n")
# Ensure that each data set was processed only once
stopifnot(all(table(ldf$ID) %in% c(3, 4, 5, 6)))
## Get optimum per simulation run for the Anticluster Editing objective
maxima <- ldf %>%
group_by(ID) %>%
summarise(maximum = max(dist_obj))
## Compute relative objective
merged <- ldf %>%
inner_join(maxima) %>%
mutate(rel_value = dist_obj / maximum) %>%
as_tibble()
# Average performance per simulation run across the different sample
# categories
aggregated_objectives <- merged %>%
mutate(N_category = factor(
case_when(N <= 20 ~ 1,
N > 20 & N <= 40 ~ 2,
TRUE  ~ 3),
levels = 1:3, labels = c("N <= 20", "20 < N <= 40", "N > 40"))
) %>%
group_by(method, N_category) %>%
summarise(Objective = mean(rel_value), D_Means = mean(means_obj), D_SD = mean(sd_obj)) %>%
arrange(N_category, -Objective) %>%
na.omit() %>%
rename(N = N_category)
# rename methods
aggregated_objectives <- aggregated_objectives %>%
ungroup %>%
mutate(
method = case_when(
method == "ilp-exact" ~ "ACE-ILP",
method == "ilp-preclustered" ~ "ACE-ILP/Preclustering",
method == "ace-exchange" ~ "ACE-Exchange",
method == "matching" ~ "Matching",
method == "k-means-exchange" ~ "K-Means-Anticlustering",
method == "random" ~ "Random assignment",
TRUE ~ "should not happen"
)
)
## Write results table
write.table(aggregated_objectives, paste0("results-K", K, "-aggregated.csv"),
quote = TRUE, row.names = FALSE, sep = ";")
}
library(anticlust)
generate_partitions(2, 4)
tt <- c(1, 3, 7, 9)
parts <- generate_partitions(2, 4)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 3, 9, 11)
sapply(parts, anticlust:::obj_value_distance, data = tt)
sapply(parts, anticlust:::distance_objective_, data = dist(tt)^2)
sapply(parts, anticlust:::distance_objective_, data = as.matrix(dist(tt))^2)
as.matrix(dist(tt))^2
tt <- c(1, 3, 3, 7, 9, 9)
parts <- generate_partitions(2, 6)
sapply(parts, anticlust:::obj_value_distance, data = tt)
parts[[3]]
tt
parts[[4]]
tt <- c(1, 3, 5, 7, 9, 11)
sapply(parts, anticlust:::obj_value_distance, data = tt)
parts[[6]]
parts[[7]]
parts[[8]]
parts[[9]]
parts[[10]]
tt <- c(1, 3, 5, 9, 11, 13)
sapply(parts, anticlust:::obj_value_distance, data = tt)
sapply(parts, anticlust:::variance_objective_, data = tt)
sapply(parts, anticlust:::variance_objective_, data = as.matrix(tt))
sapply(parts, anticlust:::variance_objective_, data = as.matrix(tt)) == 112
max(sapply(parts, anticlust:::variance_objective_, data = as.matrix(tt)))
sapply(parts, anticlust:::distance_objective_, data = as.matrix(dist(tt))^2)
# Load required packages
library(anticlust)
source("0-functions-matching.R")
source("0-functions-anticlustering-methods.R")
source("0-functions-generate-data.R")
# Repeat the simulation for K = 2 and K = 3
for (K in 2) {
# Select all data files
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated that has been conducted previously
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# Uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 100)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
sapply(parts, anticlust:::distance_objective_, data = as.matrix(dist(tt))^2)
# Load required packages
library(anticlust)
source("0-functions-matching.R")
source("0-functions-anticlustering-methods.R")
source("0-functions-generate-data.R")
# Repeat the simulation for K = 2 and K = 3
for (K in 2) {
# Select all data files
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated that has been conducted previously
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
# Uncomment the following line and exchange the value of the size
# argument if not all 5000 file should be processed at the same time
files <- sample(files, size = 2000)
## Apply all methods to the data sets
start <- Sys.time()
lapply(files, anticluster_data, path = path, K = K)
print(Sys.time() - start)
}
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
source("4-Aggregate-Results.R")
sapply(parts, anticlust:::distance_objective_, data = as.matrix(dist(tt))^2)
tt <- c(1, 2, 3, 4)
parts <- generate_partitions(2, 4)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 2, 5, 10)
sapply(parts, anticlust:::obj_value_distance, data = tt)
parts
tt <- c(1, 4, 5, 10)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 5, 5, 10)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 5, 5, 15)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 2, 7, 9)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 2, 7, 11)
sapply(parts, anticlust:::obj_value_distance, data = tt)
tt <- c(1, 2, 7, 1000)
sapply(parts, anticlust:::obj_value_distance, data = tt)
sapply(parts, anticlust:::obj_value_distance, data = rnorm(4))
sapply(parts, anticlust:::obj_value_distance, data = rnorm(4))
sapply(parts, anticlust:::obj_value_distance, data = rnorm(4))
sapply(parts, anticlust:::obj_value_distance, data = rnorm(4))
sapply(parts, anticlust:::obj_value_distance, data = rnorm(4))
sapply(parts, anticlust:::obj_value_distance, data = matrix(rnorm(8), ncol = 2))
sapply(parts, anticlust:::obj_value_distance, data = matrix(rnorm(8), ncol = 2))
matrix(
c(5, 21,
4, 19,
3, 19,
3, 18)
)
matrix(
c(5, 21,
4, 19,
3, 19,
3, 18),
ncol = 2
)
matrix(
c(5, 21,
4, 19,
3, 19,
3, 18),
ncol = 2,
byrow = TRUE
)
tt <- matrix(
c(5, 21,
4, 19,
3, 19,
3, 18),
ncol = 2,
byrow = TRUE
)
tt
sapply(parts, anticlust:::obj_value_distance, data = tt)
parts
sapply(parts, anticlust:::variance_objective_, data = tt)
dist(tt)
balanced_clustering(tt, method = "ilp", K = 2)
balanced_clustering(tt, method = "ilp", K = 2)
balanced_clustering(tt, method = "ilp", K = 2)
# For the existing data, call method, compute objectives, and aggregate results
source("2-Call-Methods.R")
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
K = 3
# Select all data files
n_Clusters <- paste0("K", K)
path <- paste0("./datasets/", n_Clusters, "/")
files <- paste0(list.files(path = path))
## Check that no analysis is repeated that has been conducted previously
results_file <- paste0("results-", n_Clusters, "-solutions.csv")
if (file.exists(results_file)) {
previous_tests <- as.character(unique(read.csv(results_file, sep = ";")$file))
previous_tests <- paste0(previous_tests, ".csv")
already_done <- files %in% previous_tests
## Only select tests that have not been tested before!
files <- files[!already_done]
}
## Apply all methods to the data sets
message("Starting to work on ", length(files), " data sets")
# For the existing data, call method, compute objectives, and aggregate results
source("2-Call-Methods.R")
start <- Sys.time()
source("3-Compute-Objectives.R")
source("4-Aggregate-Results.R")
print(Sys.time() - start)
# Load required packages
library(anticlust)
library(dplyr)
## Analyze data for K = 2 and K = 3 and write results to file
for (K in 3) {
results_file <- paste0("results-K", K, "-objectives-raw.csv")
## Read test results
ldf <- read.csv(results_file, sep = ";", stringsAsFactors = FALSE)
message("Number of simulation runs for K = ", K , ": ", length(unique(ldf$ID)), "\n")
# Ensure that each data set was processed only once
stopifnot(all(table(ldf$ID) %in% c(3, 4, 5, 6)))
## Get optimum per simulation run for the Anticluster Editing objective
maxima <- ldf %>%
group_by(ID) %>%
summarise(maximum = max(dist_obj))
## Compute relative objective
merged <- ldf %>%
inner_join(maxima) %>%
mutate(rel_value = dist_obj / maximum) %>%
as_tibble()
# Average performance per simulation run across the different sample
# categories
aggregated_objectives <- merged %>%
mutate(N_category = factor(
case_when(N <= 20 ~ 1,
N > 20 & N <= 40 ~ 2,
TRUE  ~ 3),
levels = 1:3, labels = c("N <= 20", "20 < N <= 40", "N > 40"))
) %>%
group_by(method, N_category) %>%
summarise(Objective = mean(rel_value), D_Means = mean(means_obj), D_SD = mean(sd_obj)) %>%
arrange(N_category, -Objective) %>%
na.omit() %>%
rename(N = N_category)
# rename methods
aggregated_objectives <- aggregated_objectives %>%
ungroup %>%
mutate(
method = case_when(
method == "ilp-exact" ~ "ACE-ILP",
method == "ilp-preclustered" ~ "ACE-ILP/Preclustering",
method == "ace-exchange" ~ "ACE-Exchange",
method == "matching" ~ "Matching",
method == "k-means-exchange" ~ "K-Means-Anticlustering",
method == "random" ~ "Random assignment",
TRUE ~ "should not happen"
)
)
## Write results table
write.table(aggregated_objectives, paste0("results-K", K, "-aggregated.csv"),
quote = TRUE, row.names = FALSE, sep = ";")
}
source("4-Aggregate-Results.R")
